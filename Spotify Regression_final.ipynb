{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "c0c3cab6",
      "cell_type": "markdown",
      "source": "# **Spotify Song Popularity Prediction**\n\n---\n\n## Table of contents\n\n1. [Introduction](#introduction)  \n2. [License](#license)  \n3. [Required libraries](#required-libraries)  \n4. [Problem domain](#problem-domain)  \n5. [Step 1: Data Overview](#step1)  \n6. [Step 2: Checking for Missing Values and Basic Cleaning](#step2)  \n7. [Step 3: Exploratory Data Analysis](#step3)   \n8. [Step 4: Preparing Data for Modeling](#step4)  \n9. [Step 5: Splitting the Dataset](#step5) \n10. [Step 6: Data Preprocessing](#step6) \n11. [Step 7: Baseline and Advanced Modeling](#step7)  \n    •\tLinear Regression\n\t•\tRandom Forest Regressor\n\t•\tXGBoost Regressor\n12. [Conclusions](#conclusions)  \n13. [Acknowledgements](#acknowledgements)\n\n---\n\n<a id=\"introduction\"></a>\n## Introduction\n\nThis report aimes at predicting the popularity of Spotify songs using a variety of numeric and categorical features. The main objective was to build and compare regression models that could accurately forecast a track’s popularity score (labeled as pop in the dataset). By carefully cleaning the data, engineering relevant features, and tuning multiple models, we sought to determine which learning algorithm could best generalize to unseen songs.\n\nThe dataset under study contained columns representing several audio and metadata attributes: tempo (bpm), loudness (dB), danceability (dnce), valence (val), energy (nrgy), acousticness (acous), speechiness (spch), release year (year), and others. We combined these numeric columns with basic categorical features (artist name and top genre) to form predictive inputs for a regression approach, using linear regression, random forest and XGBoost models. Finally, we measured performance using the Root Mean Squared Error (RMSE), which is well-suited to penalizing large prediction errors.\nThroughout the analysis, we used boxplots and histograms for visualizing the distribution of features and identifying outliers, correlation analysis to understand the relationships among variables, and a learning curve to assess how each model’s performance might improve (or plateau) as the training set size increases. These steps collectively helped us refine the feature set, transform skewed data, and compare modeling approaches with greater confidence.\n\n---\n\n<a id=\"license\"></a>\n## License\nData from : [Kaggle Spotify dataset]( https://www.kaggle.com/competitions/cs-985-6-spotify-regression-problem-2025/overview)”. \n\n---\n\n<a id=\"required-libraries\"></a>\n## Required libraries\n\nBelow are the required libraries for this project, the main libraries used here include:\n\n- **Numpy** and **Pandas**: for data manipulation and basic data structures.\n- **Matplotlib** and **Seaborn**: for plotting and visualisations.\n- **Scikit-learn**: for machine learning pipelines, transformations, and modelling.\n- **XGBoost**: for advanced boosting-based regression.\n---\n",
      "metadata": {}
    },
    {
      "id": "63ef4ca7",
      "cell_type": "code",
      "source": "#basic libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport copy\n\n#plotting libraries\nimport matplotlib\n%matplotlib inline\nfrom matplotlib.pyplot import figure\nimport seaborn as sns\n\n#importing libraries we will use for our models \n\n#data prep\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.compose import TransformedTargetRegressor\n#eval\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n#models\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import FunctionTransformer",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e8df86ac",
      "cell_type": "markdown",
      "source": "<a id=\"problem-domain\"></a>\n## **The Problem Domain**\n\nSpotify is a big platform for music streaming, and each song has a pop (popularity) metric. This metric captures how many plays a track receives, its skip rate, playlist additions, and more internal calculation in this dataset. The task is to train a regression model that predicts this popularity given numeric and categorical features. Among these features:\n\n```\n•    year: The year the track was released .\n•    bpm: The tempo of the track in beats per minute.\n•    nrgy: The energy level.\n•    dnce: Danceability measure from 0–100.\n•    dB: Loudness in decibels.\n•    dur: Duration of the track in seconds.\n•    acous: Acousticness measure (0–100).\n•    spch: Speechiness measure (0–100).\n•    val: Valence measure (the general positivity).\n```\n\nWe have two datasets: a training set with 453 rows (after cleaning, we end up with 438) and a test set with 114 rows. Our goal is to build a reliable model that can generalize well and predict pop in the test set based on our training set.",
      "metadata": {}
    },
    {
      "id": "200b01a4",
      "cell_type": "markdown",
      "source": "<a id=\"step1\"></a>\n## **Step 1: Data Overview**\n\nWe began by loading two CSV files: one labeled as the training set (CS98XRegressionTrain.csv) and one as the test set (CS98XRegressionTest.csv). The training set contained 453 rows and 15 columns prior to cleaning, while the test set had 114 rows and 14 columns. An inspection with info() showed that both sets included integer, float, and object columns. The three primary object columns were title, artist, and top genre.\n\nWe also confirmed that the pop column, representing the popularity score, appeared to have valid integer data for all rows in the training set. No additional columns in the test set directly corresponded to popthat is the target variable we needed to predict.",
      "metadata": {}
    },
    {
      "id": "05b0fd64",
      "cell_type": "code",
      "source": "data_train=pd.read_csv(\"CS98XRegressionTrain.csv\")\ndata_test= pd.read_csv('CS98XRegressionTest.csv')\n\n# A quick glance of the data\ndata_columns=len(data_train.columns)\ndata_rows=len(data_train)\nprint('There are {} columns in data_train'.format(data_columns))\nprint('\\nThere are {} rows in data_train'.format(data_rows))\n\n\ndata_train.head(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "aff3b906",
      "cell_type": "code",
      "source": "data_train.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "93604853",
      "cell_type": "code",
      "source": "data_train['artist'].duplicated().value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8984029b",
      "cell_type": "markdown",
      "source": "<a id=\"step2\"></a>\n## Step 2: Checking for Missing Values and Basic Cleaning",
      "metadata": {}
    },
    {
      "id": "10e1f29c",
      "cell_type": "markdown",
      "source": "This code segment determines the total number of missing entries in both the training and test datasets, identifies which rows have null values in the top genre column, and removes those rows from the training set. The test set is checked for missing data but remains otherwise unchanged.",
      "metadata": {}
    },
    {
      "id": "e8e05f33",
      "cell_type": "code",
      "source": "# Missing values\nn_missing=data_train.isnull().sum().sum()\nprint('We have {} values missing from the training data.'.format(n_missing))\n\nn_missing_test=data_test.isnull().sum().sum()\nprint('We have {} values missing from the testing data'.format(n_missing_test))\n\nmissing_values=data_train.loc[data_train['top genre'].isnull() == True]\nmissing_values",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d2efdee7",
      "cell_type": "code",
      "source": "data_train.isnull().sum()\n\n# # Drop missing rows in the training set\n# data_train=data_train.dropna()\n\n# data_test.isnull().any()\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b8c91f5e",
      "cell_type": "code",
      "source": "data_test.isnull().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "31595e1d",
      "cell_type": "markdown",
      "source": "<a id=\"step3\"></a>\n## Step 3: Exploratory Data Analysis",
      "metadata": {}
    },
    {
      "id": "e1d10e7d",
      "cell_type": "markdown",
      "source": "With the training data trimmed down to 438 rows, we performed an exploratory data analysis to better understand the distributions and correlations.\n\nThis section explores the dataset’s distribution and relationships between features. Histograms visualize the distribution of numerical variables, while a correlation matrix identifies features most associated with popularity (pop). Violin plots provide insights into feature distributions, and boxplots highlight outliers. Additionally, scatterplots help visualize the relationships between individual features and the target variable, aiding in feature selection and transformation decisions.\n\n1.\t**Histograms** of key features (nrgy, dnce, dB, acous) showed that some were reasonably symmetric, while others (like live and spch) were more skewed.\n\n2.\tA **correlation matrix** indicated that some variables had positive correlations with pop. Notably, dur (duration), nrgy, and dB (loudness) correlated positively with popularity, while acousticness (acous) correlated negatively. This provided early clues that well-produced, loud, and energetic songs may be more popular.\n\n3.\t**Violin plots** and **boxplots** for continuous variables further demonstrated skewed distributions in a few features, suggesting that transformations might help the model. Some outliers for dur and dnce also appeared, though not severe enough to remove.\n",
      "metadata": {}
    },
    {
      "id": "a7062db5",
      "cell_type": "code",
      "source": "data_train.hist(bins=10,figsize=(15,20))\nplt.show()\nprint(\"An inbalanced data like spch live are both right skewed\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a85f6a19",
      "cell_type": "markdown",
      "source": "We then prepare numeric-only data (excluding text columns like title and artist) and check correlation with the pop target:",
      "metadata": {}
    },
    {
      "id": "0b69db11",
      "cell_type": "code",
      "source": "num_data_train= data_train.drop(columns=['title','artist','top genre'])\nnum_data_train.head(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8a5f7155",
      "cell_type": "code",
      "source": "corr_matrix=num_data_train.corr()\ncorr_matrix[\"pop\"].sort_values(ascending=False)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e60dac88",
      "cell_type": "code",
      "source": "#Correlation matrix to see any relation to the variable POP\npop_correlation=corr_matrix[\"pop\"]\nsns.heatmap(pop_correlation.to_frame(), annot=True, cmap='coolwarm', center=0, fmt=\".2f\", cbar=False)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "303b41bd",
      "cell_type": "code",
      "source": "print(\"From the correlation matrix, we can see that:\")\nprint(\"Positive correlation: dur, dB, nrgy, dnce, spch\")\nprint(\"Negative correlation: val, live, year, acous\")\nprint(\"It seems like popular songs are: less acoustic, longer duration, louder\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "97c65cd4",
      "cell_type": "markdown",
      "source": "Visual check via a violin plot:",
      "metadata": {}
    },
    {
      "id": "d5b99318",
      "cell_type": "code",
      "source": "def plot_violinplots(data, features):\n    fig, axes = plt.subplots(nrows=2, ncols=6, figsize=(20, 8))\n    axes = axes.ravel()  \n    \n    for i, feature in enumerate(features):\n        color = np.random.rand(3,)  \n        sns.violinplot(x=data[feature], ax=axes[i], color=color)\n        axes[i].set_title(feature)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Example usage:\nmy_features = ['spch','acous','dur','val','live','dB','dnce','nrgy','bpm','year','pop']\nplot_violinplots(data_train, my_features)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2482894a",
      "cell_type": "markdown",
      "source": "Function to plot some summary stats and relationships for a selected feature vs. the target:",
      "metadata": {}
    },
    {
      "id": "3b89c88b",
      "cell_type": "code",
      "source": "def feature_plotting(feature_name, target):\n\n  colour = np.random.rand(3,)\n\n  print('Summary stats for {}:\\n'.format(feature_name) )\n  print(data_train[feature_name].describe())\n  plt.show()\n  print('\\nBoxplot will show us spread and highlight outliers:\\n')\n  sns.boxplot(x = data_train [feature_name], color = colour)\n  plt.show()\n  print('\\nScatterplot will show us relationship between {} and {}:\\n'.format(feature_name, target))\n  sns.scatterplot(data=data_train,x = data_train[feature_name], y = data_train[target], color = colour)\n  plt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bca6e40d",
      "cell_type": "code",
      "source": "feature_plotting('dur','pop')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "244796ea",
      "cell_type": "markdown",
      "source": "<a id=\"step5\"></a>\n## Step 5: Feature Engineering\n\nThis step focuses on preparing the dataset for machine learning by splitting, transforming, and encoding the data appropriately.\n\n#### Train-Test Splitting \nThe function train_test() separates the dataset into training and testing sets, ensuring that transformations applied to training data do not affect the raw test set. If make_copy=True, deep copies of the datasets are created to prevent accidental modifications. The function removes the target variable (pop) from the training features while keeping it in y_train, and also drops unnecessary columns from both datasets.\n\n#### Feature Scaling and Transformation\nTo ensure features are on a comparable scale, transform_features() applies either standard scaling (zero mean, unit variance) or power transformation (reducing skewness). For training data, scalers are fitted and stored in a dictionary, which is later applied to the test set to avoid data leakage.\n\n#### Encoding Categorical Variables\nSince machine learning models typically require numerical inputs, label_encoding() converts categorical features (artist, top genre) into integer values. A LabelEncoder is trained on the combined training and test data to ensure consistency in encoding.\n\n#### Powertransformer  and Logarithm Transformations\nThe powertransformer are used to handle inbalance data because Features with a long tail will be replaced by their logarithm, as most models prefer features with roughly uniform or Gaussian distributions.\n\nFunctions log_transform() and inverse_transform() provide optional log transformations to stabilize variance in features or predictions.\n\nThis preprocessing step ensures that all features are scaled, encoded, and formatted properly before model training, reducing bias from feature magnitudes and improving model generalizability.",
      "metadata": {}
    },
    {
      "id": "f36ec8f1",
      "cell_type": "code",
      "source": "#Slpliting dataset\ndef train_test(train_data, test_data, target, dropping_columns, make_copy=False):\n    if make_copy:\n        train_data = copy.deepcopy(train_data)\n        test_data = copy.deepcopy(test_data)\n    \n    X_train = train_data.drop(target, axis=1)\n    y_train = train_data[target]S\n    X_test = test_data.drop(dropping_columns, axis=1)\n    X_train = X_train.drop(dropping_columns, axis=1)\n    \n    return X_train, y_train, X_test",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "32c78a06",
      "cell_type": "code",
      "source": "#Applying scalling transformation\ndef transform_features(df, columns, transformer_name, transf_dict):\n  #function for scaling or normalising specified features\n\n  if transf_dict is None:\n\n    if transformer_name == 'Standard':\n      transf = preprocessing.StandardScaler()\n  \n    elif transformer_name == 'PowerTransformer':\n      transf = preprocessing.PowerTransformer()\n  \n    #make a dictionary of the fitted transformer so that we can use training scales for testing data\n\n    transf_dict = {}\n    \n    for col in columns:\n      col_transf = copy.deepcopy(transf)\n      col_transf = col_transf.fit(df[[col]])\n      df[col] = col_transf.transform(df[[col]])\n      transf_dict[col] = col_transf\n\t\n  else:\n    for col in columns:\n      transf = transf_dict.get(col)\n      df[col] = transf.transform(df[[col]])\n    \n    return df\n\n  return df, transf_dict #returning dictionary and df with scaled features",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "41b97595",
      "cell_type": "code",
      "source": "#Label encoding for categorical features\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\n\ndef label_encoding(X_train, X_test, column):\n   \n    imputer = SimpleImputer(strategy='most_frequent')  \n    X_train[column] = imputer.fit_transform(X_train[[column]]).ravel()\n    X_test[column] = imputer.transform(X_test[[column]]).ravel()\n    \n    train_len = len(X_train)\n    label_encoder = LabelEncoder()\n    full_data = pd.concat([X_train[column], X_test[column]], axis=0, ignore_index=True)\n    full_data_enc = label_encoder.fit_transform(full_data.values)\n    \n    X_train_enc = full_data_enc[:train_len]\n    X_test_enc = full_data_enc[train_len:]\n    \n    return X_train_enc, X_test_enc, label_encoder",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "306c6bb1",
      "cell_type": "code",
      "source": "#Logarithmic and exponential transformation\ndef log_transform(x):\n    return np.log(x)\n\ndef inverse_transform(x):\n    return np.exp(x)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4717e58b",
      "cell_type": "code",
      "source": "#Crossvalidation Scores\ndef display_scores(scores, negative_result=False):\n    if negative_result:\n        scores = np.array([abs(x) for x in scores])\n    \n    print(\"Scores:\")\n    for i, score in enumerate(scores):\n        print('Fold {} - {:.3f}'.format(i, score))\n    \n    print(\"\\nMean: {:.3f}\".format(scores.mean()))\n    print(\"Standard deviation: {:.3f}\".format(scores.std()))\n    print('\\n')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "05fb544f",
      "cell_type": "code",
      "source": "#Function to compute and visualize the learning curve\ndef learning_curve(model, X, y, xgb=False):\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n    train_errors, val_errors = [], []\n    \n    if xgb:\n        y_train = y_train.values.ravel()\n    \n    for m in range(1, X_train.shape[0]):\n        model.fit(X_train[:m], y_train[:m])\n        y_train_predict = model.predict(X_train[:m])\n        y_val_predict = model.predict(X_val)\n        \n        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n        val_errors.append(mean_squared_error(y_val, y_val_predict))\n    \n    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c3782238",
      "cell_type": "code",
      "source": "#Function learning curve\ndef plot_learning_curve(model, X, y, xgb=False):\n    plt.figure(figsize=(6, 4), dpi=120)\n    learning_curve(model, X, y, xgb=xgb)\n    plt.ylim(top=20)\n    plt.legend()\n    plt.xlabel('Training set size')\n    plt.ylabel('RMSE')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "41dbb4df",
      "cell_type": "code",
      "source": "#Prepare dataset\ntarget = 'pop'\ndropping_columns = ['Id', 'title']\nX_train, y_train, X_test = train_test(data_train, data_test, target, dropping_columns, make_copy=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5fc43876",
      "cell_type": "code",
      "source": "#Dataset info\nprint('There are {} rows in X_train'.format(len(X_train)))\nprint('There are {} columns in X_train'.format(len(X_train.columns)))\nprint('There are {} rows in X_test'.format(len(X_test)))\nX_train",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b439c5e5",
      "cell_type": "code",
      "source": "from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ef2eba20",
      "cell_type": "markdown",
      "source": "<a id=\"step6\"></a>\n## Step 6: Data Preprocessing\n\nTo enhance feature representation, two new variables were engineered: new1, a weighted combination of loudness (dB), duration (dur), and danceability (dnce), and new2, a product of danceability (dnce) and energy (nrgy). Categorical variables, specifically artist and top genre, were label-encoded to convert them into numerical format.\n\nFor continuous variables, a Power Transformer was applied to mitigate skewness and normalize feature distributions, followed by Standard Scaling to ensure zero mean and unit variance. These transformations were fitted on the training data and subsequently applied to the test set to prevent data leakage.",
      "metadata": {}
    },
    {
      "id": "a359a449",
      "cell_type": "code",
      "source": "# data prep\nX_train[\"new1\"]=0.4*X_train[\"dB\"]+0.4*X_train[\"dur\"]+0.2*X_train[\"dnce\"]#try 1\nX_test[\"new1\"]=0.4*X_test[\"dB\"]+0.4*X_test[\"dur\"]+0.2*X_test[\"dnce\"]#try 1\n\nX_train[\"new2\"]=X_train[\"dnce\"]*X_train[\"nrgy\"] # try 2\nX_test[\"new2\"]=X_test[\"dnce\"]*X_test[\"nrgy\"] # try 2\n\nX_train['nrgy_dB_ratio'] = X_train['nrgy'] / (X_train['dB'] + 1e-6) #try3\nX_test['nrgy_dB_ratio'] = X_test['nrgy'] / (X_test['dB'] + 1e-6) #try3\n\nX_train['dur_nrgy'] = X_train['dur'] * X_train['nrgy'] #try4\nX_test['dur_nrgy'] = X_test['dur'] * X_test['nrgy'] #try4\n\n\n#label encod -artist\ncolumn1='artist'\nX_train_enc_artist,X_test_enc_artist,label_encoder_art=label_encoding(X_train,X_test,column1)\nX_train['artist']=X_train_enc_artist\nX_test['artist']=X_test_enc_artist\n\n#label encod -top genre\ncolumn2='top genre'\nX_train_enc_genre,X_test_enc_genre,label_encoder_genre=label_encoding(X_train,X_test,column2)\nX_train['top genre']=X_train_enc_genre\nX_test['top genre']=X_test_enc_genre\n\n#scaling and transforming conitnuous data\ncont_data = ['year', 'bpm','nrgy',\t'dnce',\t'dB',\t'live',\t'val', 'dur',\t'acous', 'spch','new1','new2','nrgy_dB_ratio','dur_nrgy','log_nrgy']\n\n#Power transforming continuous features\nX_train, powertf_dict = transform_features(X_train, cont_data, 'PowerTransformer', transf_dict = None)\nX_test = transform_features(X_test, cont_data, 'PowerTransformer', transf_dict = powertf_dict)\n\n#Standardizing continuous features\nX_train, standard_scalers = transform_features(X_train, cont_data, 'Standard', transf_dict = None)\nX_test = transform_features(X_test, cont_data, 'Standard', transf_dict = standard_scalers)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bac44d81",
      "cell_type": "code",
      "source": "X_train.hist(bins=10,figsize=(15,20))\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d1feeb62",
      "cell_type": "markdown",
      "source": "<a id=\"step7\"></a>\n## Step 7: Baseline and Advanced Modeling\nWe evaluated three primary regression models: **Linear Regression**, **Random Forest Regressor**, and **XGBoost Regressor**.\n\n## Linear Regression\nA Linear Regression model was trained on the dataset to establish a baseline for predicting song popularity. The model’s performance was assessed using Root Mean Squared Error (RMSE) and 10-fold cross-validation to evaluate its generalization ability.\n\n#### Performance Metrics:\n\n\t•The training RMSE was 10.473, indicating a moderate level of prediction error.\n\t•Cross-validation results across 10 folds showed an average RMSE of 10.879, with a standard deviation of 1.595, this shows some variability in performance across different subsets of data.\n\t•Individual fold RMSE values ranged from 7.861 to 13.664.\n\n#### Learning Curve Analysis:\n\n\t•The learning curve reveals that both training and validation errors stabilize as the dataset size increases, but they remain relatively high, suggesting underfitting (high bias).\n\t•The training error starts low but quickly increases, converging near the validation error, which indicates that adding more data alone may not significantly improve model performance.\n\t•The gap between the two curves is small, meaning that overfitting is not a major concern, but the model may be too simple to fully capture the underlying relationships in the data.",
      "metadata": {}
    },
    {
      "id": "5c2c0904",
      "cell_type": "code",
      "source": "lin_reg=LinearRegression()\n# lin_reg = TransformedTargetRegressor(regressor = lin_reg, func = log_transform, inverse_func = inverse_transform)\nlin_reg.fit(X_train, y_train)\n\ny_lin_eval = lin_reg.predict(X_train) # Change to X_test\n\n#model evaluation\nlin_mse = mean_squared_error(y_lin_eval, y_train)   \nlin_rmse = np.sqrt(lin_mse)                        \n\nlin_cv_scores = cross_val_score(lin_reg, X_train, y_train,\nscoring=\"neg_root_mean_squared_error\", cv=10)\n\n\nprint('Cross Validation')\ndisplay_scores(lin_cv_scores, negative_result = True)\n\n\nprint('The RMSE of Linear Regression is: {:.3f}\\n'.format(lin_rmse))\n\n#plotting the learning curve\n\nprint('Learning Curve for Linear Regression model:\\n')\n\ntrain_errors = plot_learning_curve(lin_reg, X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "478b214a",
      "cell_type": "markdown",
      "source": "## Random Forest Regressor\n\nA Random Forest Regressor (RFR) was trained using 300 trees, with no maximum depth restriction and bootstrap sampling enabled. The model was evaluated using Root Mean Squared Error (RMSE) and 10-fold cross-validation to assess its predictive performance and generalization ability.\n\n#### Performance Metrics:\n\t•The training RMSE was 3.937, significantly lower than the validation scores, indicating strong performance on the training data.\n\t•Cross-validation results yielded an average RMSE of 10.744, with a standard deviation of 1.250, showing lower variability compared to linear regression.\n\t•Fold-wise RMSE values ranged from 8.927 to 12.577, indicating that the model is more stable.\n\n#### Learning Curve Analysis:\n\t•The learning curve shows a clear separation between training and validation errors, suggesting overfitting—the model performs well on training data but struggles to generalize to unseen data.\n\t•The training error remains low, meaning the model captures complex patterns in the training set.",
      "metadata": {}
    },
    {
      "id": "cae4ff52",
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestRegressor\n\nrfr_reg = RandomForestRegressor(\n    n_estimators=450,      \n    max_depth=None,\n    bootstrap=True, \n    random_state=42        \n)\n\nrfr_reg.fit(X_train, y_train)\n\ny_rfr_eval = rfr_reg.predict(X_train)\ny_pred_best=rfr_reg.predict(X_test)\n# --- MSE, then take sqrt for RMSE ---\nrfr_mse = mean_squared_error(y_train, y_rfr_eval) \nrfr_rmse = np.sqrt(rfr_mse)\n\nrfr_cv_scores = cross_val_score(rfr_reg, X_train, y_train,\nscoring=\"neg_root_mean_squared_error\", cv=10)\n\nprint('Cross Validation')\ndisplay_scores(rfr_cv_scores, negative_result = True)\n\nprint('The RMSE of Rfr Regression is: {:.3f}\\n'.format(rfr_rmse))\n\n#plotting the learning curve\nprint('Learning Curve for Rfr Regression model:\\n')\nplot_learning_curve(rfr_reg, X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4763bd92",
      "cell_type": "markdown",
      "source": "## XGBoost Regressor\n\nAn XGBoost Regressor was trained with moderate regularization (reg_lambda=2, reg_alpha=1) and hyperparameters such as max_depth=4 and n_estimators=120, wrapped in a log-transform via TransformedTargetRegressor to help linearize the target variable.\n\nPerformance Metrics:\n\n\t•Training RMSE: 3.937, indicating the model fits the training data very close.\n\t•Cross-Validation: The average RMSE over 10 folds is 11.145 (±1.537).\n\t•Fold RMSE scores range from 8.927 to 13.382, reflects moderate variability across different splits of the data.\n\nLearning Curve Insights:\n\n\t•The training error decreases rapidly and remains low, while the validation error is notably higher.\n\t",
      "metadata": {}
    },
    {
      "id": "f720b961",
      "cell_type": "code",
      "source": "xgb_reg = XGBRegressor(max_depth=6, n_estimators=120, reg_lambda=2, reg_alpha=1, subsample=0.925, colsample_bytree=0.925, verbosity = 0)\n\nxgb_reg = TransformedTargetRegressor(regressor = xgb_reg, func = log_transform, inverse_func = inverse_transform)\n\nxgb_reg.fit(X_train, y_train)\n\n#model prediction\ny_pred = xgb_reg.predict(X_test)\ny_xgb_eval = xgb_reg.predict(X_train)\n\nxgb_mse = mean_squared_error(y_train, y_xgb_eval) \nxgb_rmse  = np.sqrt(rfr_mse)\n\nxgb_cv_scores = cross_val_score(xgb_reg, X_train, y_train,\nscoring=\"neg_root_mean_squared_error\", cv=10)\n\nprint('Cross Validation')\ndisplay_scores(xgb_cv_scores, negative_result = True)\n\n#print('Learning Curve for XGBoost model:\\n')\n#plot_learning_curve(xgb_reg, X_train, y_train)\n\nprint('The training RMSE of XGBoost Regression is: {:.3f}'.format(xgb_rmse))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "866e0301",
      "cell_type": "code",
      "source": "training_RMSE = [lin_rmse, xgb_rmse,rfr_rmse] \ntraining_RMSE = pd.DataFrame({'Linear Training RMSE':lin_rmse, 'XGBoost RMSE':xgb_rmse, 'RandomForest RMSE':rfr_rmse}, index = training_RMSE)\n\nfig, ax = plt.subplots(figsize = (10,10))\nsns.barplot(data = training_RMSE)\nax.set(xlabel='Model', ylabel=' Training RMSE')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f3fc74b6",
      "cell_type": "markdown",
      "source": "*XGBoost RMSE and Random Forest RMSE have higher trainning rmse than linear model due to overfitting. Betweem these two fonts, randomforest has a lightly better performance than XGBoost.*",
      "metadata": {}
    },
    {
      "id": "a92cf994",
      "cell_type": "markdown",
      "source": "### Finalizing Predictions for Submission",
      "metadata": {}
    },
    {
      "id": "1d493f87",
      "cell_type": "code",
      "source": "\n\npredictions = pd.DataFrame(data = y_pred, columns = ['pop'])\n\nid = pd.DataFrame(data = data_test['Id'], columns = ['Id'])\npredictions = pd.merge(id, predictions, right_index = True, left_index = True)\n\npredictions\npredictions.to_csv('spotify_regression.csv', index=False)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "27fc0767",
      "cell_type": "markdown",
      "source": "<a id=\"conclusions\"></a>\n## Conclusions\n\nIn this project, we explored how numeric and categorical features can be leveraged to predict the popularity of Spotify songs. By iteratively cleaning the data, engineering new features (e.g., combining duration, loudness, and danceability), and applying transformations to reduce skewness and standardize distributions, we ensured that our dataset was well-prepared for modeling.\n\nThree different regression models—Linear Regression, Random Forest, and XGBoost—were then trained and assessed using RMSE as the key performance metric:\n\n\t1.Linear Regression provided a good baseline with relatively narrow gaps between training and validation errors.\n\t2.Random Forest demonstrated strong training performance and captured more complex relationships in the data but faced overfitting, as evident in the gap between training and validation RMSE.\n\t3.XGBoost offered similarly powerful predictive capabilities and allowed for regularization, yet it also exhibited overfitting. \n\nOverall, each model contributed valuable insights into the data’s underlying structure and helped identify potential approaches to improving prediction. However, the results may also be influenced by the limitations of the dataset itself, such as the relatively small sample size and potential biases in Spotify’s popularity metric, which is influenced by internal algorithms and external factors like playlist placement and marketing. A larger, more diverse dataset including more songs from various genres, user engagement metrics, or alternative sources could improve model performance and provide a more comprehensive understanding of song popularity. The Randomforest regression model that we model get to the 5th place in the competition finally.",
      "metadata": {}
    }
  ]
}